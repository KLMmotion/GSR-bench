"""
Token åˆ†æå™¨ï¼šåˆ†æå’Œç»Ÿè®¡ token ä½¿ç”¨æƒ…å†µ
Created: 2024-01-05
"""

import sys
import os
from typing import Dict, Any, Optional

try:
    from langchain_core.messages import AIMessage
    LANGCHAIN_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: LangChain ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿ AIMessage")
    LANGCHAIN_AVAILABLE = False

    class AIMessage:
        def __init__(self, content):
            self.content = content

try:
    from config import TOKEN_CONFIG
except ImportError:
    from langgraph_agent.config import TOKEN_CONFIG


class TokenAnalyzer:
    """
    Token åˆ†æå™¨ï¼šä¼°ç®—å’Œåˆ†æ token ä½¿ç”¨æƒ…å†µ
    """
    
    def __init__(self):
        self.chars_per_token = TOKEN_CONFIG.get("chars_per_token", 3.5)
        self.enable_analysis = TOKEN_CONFIG.get("enable_analysis", True)
    
    def estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            int: ä¼°ç®—çš„ token æ•°é‡
        """
        if not text:
            return 0

        char_count = len(text)
        return max(1, int(char_count / self.chars_per_token))
    
    def analyze_conversation_tokens(self, result: Dict[str, Any],
                                   system_prompt: str,
                                   user_input: str):
        """
        åˆ†æå¯¹è¯å„éƒ¨åˆ†çš„ token ä½¿ç”¨æƒ…å†µ

        Args:
            result: Agent è¿”å›ç»“æœ
            system_prompt: ç³»ç»Ÿæç¤º
            user_input: ç”¨æˆ·è¾“å…¥
        """
        if not self.enable_analysis:
            return

        try:
            if isinstance(result, dict) and "messages" in result:
                messages = result["messages"]

                system_tokens = self.estimate_tokens(system_prompt)
                user_tokens = self.estimate_tokens(user_input)

                tool_tokens = 0
                history_tokens = 0
                
                for msg in messages:
                    if hasattr(msg, 'content'):
                        content = str(msg.content)
                        if "Current scene graph:" in content:
                            tool_tokens += self.estimate_tokens(content)
                        elif hasattr(msg, 'type'):
                            if msg.type == 'human' and msg.content != user_input:
                                history_tokens += self.estimate_tokens(content)
                            elif msg.type == 'ai' and "Current scene graph:" not in content:
                                history_tokens += self.estimate_tokens(content)
                
                self._print_token_breakdown(
                    system_tokens, user_tokens, tool_tokens, history_tokens
                )

                self._print_actual_token_usage(result)
                
        except Exception as e:
            print(f"ğŸ“Š Token åˆ†æå‡ºé”™: {e}")
    
    def _print_token_breakdown(self, system_tokens: int, user_tokens: int, 
                              tool_tokens: int, history_tokens: int):
        """
        æ‰“å° token åˆ†è§£ä¿¡æ¯
        
        Args:
            system_tokens: ç³»ç»Ÿæç¤º tokens
            user_tokens: ç”¨æˆ·è¾“å…¥ tokens
            tool_tokens: å·¥å…·ç»“æœ tokens
            history_tokens: å†å²å¯¹è¯ tokens
        """
        total_estimated = system_tokens + user_tokens + tool_tokens + history_tokens
        
        print(f"ğŸ“Š Token åˆ†è§£:")
        print(f"  ğŸ¯ System Prompt: ~{system_tokens} tokens")
        print(f"  ğŸ‘¤ ç”¨æˆ·æ¶ˆæ¯: ~{user_tokens} tokens")
        print(f"  ğŸ”§ å·¥å…·ç»“æœ: ~{tool_tokens} tokens")
        print(f"  ğŸ“š å†å²å¯¹è¯: ~{history_tokens} tokens")
        print(f"  ğŸ“ ä¼°ç®—æ€»è¾“å…¥: ~{total_estimated} tokens")
    
    def _print_actual_token_usage(self, result: Dict[str, Any]):
        """
        æ‰“å°å®é™… token ä½¿ç”¨æƒ…å†µ

        Args:
            result: Agent è¿”å›ç»“æœ
        """
        try:
            if isinstance(result, dict) and "messages" in result:
                for msg in reversed(result["messages"]):
                    if isinstance(msg, AIMessage):
                        usage_info = self._extract_usage_info(msg)
                        if usage_info:
                            print(f"ğŸ”¹ å®é™… Token ä½¿ç”¨: {usage_info}")
                            return

                print("ğŸ”¹ å®é™… Token ä½¿ç”¨ä¿¡æ¯ä¸å¯ç”¨")

        except Exception as e:
            print(f"ğŸ”¹ Token ç»Ÿè®¡å‡ºé”™: {e}")
    
    def _extract_usage_info(self, msg: AIMessage) -> Optional[str]:
        """
        ä» AI æ¶ˆæ¯ä¸­æå–ä½¿ç”¨æƒ…å†µä¿¡æ¯

        Args:
            msg: AI æ¶ˆæ¯

        Returns:
            Optional[str]: ä½¿ç”¨æƒ…å†µä¿¡æ¯å­—ç¬¦ä¸²
        """
        if hasattr(msg, 'usage_metadata') and msg.usage_metadata:
            usage = msg.usage_metadata
            input_tokens = usage.get('input_tokens', 'N/A')
            output_tokens = usage.get('output_tokens', 'N/A')
            total_tokens = usage.get('total_tokens', 'N/A')
            return f"è¾“å…¥={input_tokens}, è¾“å‡º={output_tokens}, æ€»è®¡={total_tokens}"

        if hasattr(msg, 'response_metadata') and msg.response_metadata:
            metadata = msg.response_metadata
            if 'token_usage' in metadata:
                return str(metadata['token_usage'])

        return None
    
    def get_token_stats(self) -> Dict[str, Any]:
        """
        è·å– token åˆ†æå™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            "chars_per_token": self.chars_per_token,
            "enable_analysis": self.enable_analysis
        }
